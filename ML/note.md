[toc]

# 概述

**假设空间**
对于一个具体问题，我们总存在各种假设，对于🍉问题，features共有色泽，根蒂，响声三个维度，而对于每一个具体维度，我们总能找到所有的可能情况，这些所有的假设就构成了假设空间。
eg: 假设三个维度各有3种可能的情况，则假设空间的规模为
	$4*4*4+1=65$ $\rightarrow$ 这里的第四种情况是和这个维度无关，取任意值都不影响最终结果，最后加一种是对前提的否定：即世界上不存在好瓜
**版本空间** ： 即和训练集一致的假设集合

# 模型评估与选择
**模型**
假设空间：$F =\{f|Y=f_\theta(X),\theta \in  \mathbb{R}^n\}$ Y: 输出空间变量, X: 输入空间变量 $\rightarrow$ 所有可能的条件概率分布或决策函数的集合, 如 $f = \omega^Tx$
方法 = 模型 + 策略 + 算法
**策略**
- 如何从假设空间中选择合适的策略 $\rightarrow$ loss function or cost function
- $L(Y,f(X))$ usually > 0 
- loss function
	- 0-1 Lf  
	- quadractic : $\Vert Y-f(x)\Vert_2$
- 风险函数, 期望损失
	- 平均意义下模型的好坏
	- 经验风险: 模型在训练数据集上的平均损失$R_{emp}(f)$
- 过拟合: 数据集样本雷同 or 数据较少
	- 结构风险最小化(SRM) $\rightarrow$ 该模型是最优模型, 
	- 增加衡量复杂度的正则化项 	
		$\mathop{min}\limits_{f \in F} \frac{R}{N}\sum_{i=1}、^n L(y_i,x_i)+ \lambda * J(f)$			$\rightarrow$ 这里应该有个learning rate\
		
**优化算法**
- 有解析解/闭式解
- sgd, adam...
- 泛化误差: unseen sets 上的误差
评估方法
- 保持数据分布一致性(分层采样)
- 多次重复划分(100次随机划分)
- 测试集不能大也不能小($\frac{1}{5}\rightarrow\frac{1}{3}$)
	- K-折交叉验证 (k-1个用来训练, 一个用来测试)
	- 自助法: 改变数据分布?  在m个数据中抽取m次
	- 用验证集调整超参数(validation set): 产生若干模型, 根据评估方法进行选择
	- 样本数据 = 测试集 + 训练集 + 验证集(选择模型和调参)
- 性能度量:
	- 回归任务用均方误差
	- 错误率
	- 查准率$\frac{TP}{TP+FP}$
	- 查全率$\frac{TP}{TP+FN}$


**ROC ,AUC**
- 在进行绘图时和分类阈值相等的样例被归为正例
## **误差分析的假设检验**
交叉t检验：
- 在k折交叉验证法中将两个学习器的误差之差$\Delta_i$,作为假设检验的变量，计算方差和均值，服从自由度k-1的t分布，我们假设两学习器性能相同，则有$\overline{\Delta}=0$, 进行假设检验. 
- **5*2交叉t检验**, 在五次2折交叉验证中,计算第一次2折的结果作为均值, 然后计算每一次2折结果的方差, 即
$$
\tau_t = \frac{\mu}{\sqrt{\sum\limits_{i=1}^{5}\sigma_i*0.2}}
$$

## 多分类任务

### 类别不平衡
- 过采样：扩充样本量，加入噪声等方法
- 欠采样：减少大类的样本量
- 阈值移动：给大类和小类不同的权重

多分类任务的策略有
- O v O: 即将$C_0,C_1,...,C_n$ 每两个作为正例和负例, 从而产生$\frac{n*(n-1)}{2}$个配对的结果, 最终根据投票最多的结果进行分类
- O v R: one vs. rest 这个顾名思义, 就是把一个作为正例把剩下的都作为反例, 选择置信度最大的正例结果
- M v M: many vs. many  

# 决策树
单变量的决策树：会产生轴平行的分类面，学习任务较为复杂时需要很多段划分

# K-NN
![输入图片说明](/imgs/2024-03-26/ic7q0Crg84W8RlQB.png)
- K取值的影响
	- 一般取奇数
	- k较小时较为复杂，对噪声明显
	- k较大时容易guo'n
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTMwNDI4NTc5LDI4ODgzMzA2Miw5MTg3Nz
U2NDMsLTQxNTIxNTA0OSwtMTAwNjIwMTU3Myw0NTIxOTYxNDYs
Mzk5MTA3Njk2XX0=
-->